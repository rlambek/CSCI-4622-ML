{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Validation and Evaluation Metrics \n",
    "***\n",
    "\n",
    "In this notebook we'll investigate Scikit-Learn's functionality for performing cross-validation, plotting ROC curves, and plotting learning curves. \n",
    "\n",
    "**Note**: There are some helper functions at the bottom of this notebook.  Scroll down and execute those cells before continuing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T04:48:02.144796Z",
     "start_time": "2018-03-16T04:48:01.051195Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data Examination and Visualization\n",
    "***\n",
    "\n",
    "The data we will explore in this notebook is the so-called Spambase data, which contains features extracted from SPAM and HAM emails.  The following cell will load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T04:48:03.396618Z",
     "start_time": "2018-03-16T04:48:03.334359Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/spamdata.csv\", sep=\" \")\n",
    "X, y = data.values[:,:-1], data.values[:,-1]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: The features in in this dataset are a combination of frequency counts for select words as well as other numerical features derived from the original email text.  Some of the word-count features included are things like \n",
    "\n",
    "- `word_freq_order`: percentage of words in the email that are the word `order` \n",
    "- `word_freq_free`: percentage of words in the email that are the word `free` \n",
    "\n",
    "A few other relevant features are things like \n",
    "\n",
    "- `capital_run_length_average`: the average length of a run of capital letters \n",
    "- `capital_run_length_longest`: the longest length of a run of capital letters \n",
    "- `char_freq_!`: the number of exclamation points that appear in the email \n",
    "\n",
    "Descriptions of the rest of the features can be found [here](http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names). \n",
    "\n",
    "**Part B**: \n",
    "\n",
    "Let's visualize some of the features by plotting histograms of the features colored by whether the email is SPAM or HAM. It seems like the number of contiguous capital letters should be a good indicator of SPAM... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T04:48:05.417404Z",
     "start_time": "2018-03-16T04:48:05.009534Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_hist(data, \"capital_run_length_longest\", 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And probably also the number of exclamation points ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T04:48:07.097336Z",
     "start_time": "2018-03-16T04:48:06.716749Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_hist(data, \"char_freq_!\", 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Estimating Model Performance with Cross-Validation \n",
    "***\n",
    "\n",
    "In this section we'll use sklearn's built in cross-validation routine to estimate the accuracy of logistic regression for our data set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: First, let's set a baseline by performing a train-validation split on the data and then fitting a logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T04:48:11.816643Z",
     "start_time": "2018-03-16T04:48:11.241593Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.4, random_state=1734)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll evaluate the error on the validation set and see how well we did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T04:48:12.878525Z",
     "start_time": "2018-03-16T04:48:12.874203Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"validation accuracy: {:.3f}\".format(logreg.score(X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: OK, so suppose we're not willing to lose 40% of our data to a validation set.  We can do k-Folds Cross-Validation to use all of our data to get a more informed estimate of our classification accuracy. We can do this with sklearn's [cross_validate](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) routine.  \n",
    "\n",
    "Notice that `cross_validate` takes in an `estimator` indicating which model to use as well as a parameter `cv` which indicates how many folds to use. The function returns a dictionary containing things like `test_score`, `train_score`, `fit_time`, etc.  We're interested in the array containing `test_score` as this gives the accuracies computed on the held-out validation sets. \n",
    "\n",
    "Try it now with $k=5$ folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T17:35:39.784613Z",
     "start_time": "2018-03-16T17:35:39.232217Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate \n",
    "\n",
    "scores = cross_validate() # TODO \n",
    "\n",
    "mean_score = 0.0 # TODO \n",
    "print(\"mean score: {:.3f}\".format(mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: We might also want a 95% confidence interval for the cross-validation accuracy.  Since we only have $k=5$ samples, and we're not entirely certain that the distribution of the accuracies is normal, the safest thing to do is Bootstrap the accuracy estimate.  \n",
    "\n",
    "The one hitch here is that `cross_validate` does not accept a `random_state` flag so running `cross_validate` multiple times will yield the same results.  We can fix this by passing in a cross-validation iterator for the `cv` parameter that will randomly split the data into different folds.  Note that here we use the iterator `StratifiedKFold` because it guarantees that we get a similar proportion of each target class in each fold.  \n",
    "\n",
    "We'll do 40 runs of $5$-Folds Cross-Validation to obtain $200$ measurements of the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T04:48:26.824979Z",
     "start_time": "2018-03-16T04:48:16.612096Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "all_test_scores = []\n",
    "\n",
    "for ii in range(40):\n",
    "    scores = cross_validate(LogisticRegression(), X, y, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=None))\n",
    "    all_test_scores = all_test_scores + list(scores[\"test_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot a histogram of the accuracy measurements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T04:48:29.022710Z",
     "start_time": "2018-03-16T04:48:28.828257Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,4))\n",
    "pd.DataFrame(all_test_scores).hist(ax=ax, color=mycolors[\"blue\"], edgecolor=\"white\")\n",
    "ax.set_axisbelow(True)\n",
    "ax.set_title(\"Bootstrapped Cross-Val Accuracies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then get a 95% bootstrapped confidence interval by finding the $2.5^\\textrm{th}$ and $97.5^\\textrm{th}$ percentiles of the bootstrapped samples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T17:36:40.649751Z",
     "start_time": "2018-03-16T17:36:40.644574Z"
    }
   },
   "outputs": [],
   "source": [
    "b_mean = 0.0 # TODO \n",
    "print(\"Bootstrapped Mean: {:.3f}\".format(b_mean))\n",
    "      \n",
    "CI_low, CI_high = 0.0, 0.0 # TODO \n",
    "print(\"Bootstrapped 95% CI: [{:.3f}, {:.3f}]\".format(CI_low, CI_high))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're 95% confident that the true generalization accuracy lies between $0.91$ and $0.94$.  If we run this for many more samples then we could likely get a better estimate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Evaluating Model Performance with the ROC curve \n",
    "***\n",
    "\n",
    "Note that SPAM classification is an application in which we might want to finely tune the true positive rate and false positive rate of our classifier. \n",
    "\n",
    "**Part A**: Think about SPAM classification.  What kinds of classification errors would be the most detrimental? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Let's plot a ROC curve for our Logistic Regression classifier. Sklearn's [roc_curve]() routine computes the FPR and TPR for a range of possible thresholds in the data which you can then use to plot. Check out the documentation, and then fill in the code below to plot the curve for our Logistic Regression SPAM classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T17:37:10.024804Z",
     "start_time": "2018-03-16T17:37:09.974221Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logreg = LogisticRegression() \n",
    "logreg.fit(X_train, y_train)\n",
    "y_valid_scores = 0.0 # TODO \n",
    "\n",
    "FPR, TPR, thresholds = roc_curve() # TODO \n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8))\n",
    "ax.plot(FPR, TPR, color=mycolors[\"blue\"])\n",
    "ax.plot([0,1],[0,1], ls=\"--\", color=\"gray\")\n",
    "ax.grid(alpha=0.25)\n",
    "ax.set_xlabel(\"FPR\", fontsize=16)\n",
    "ax.set_ylabel(\"TPR\", fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Let's suppose you want to use your ROC curve to decide how your model would perform if you fixed highest the false positive rate that you're willing to accept for your classifier.  Modify your code above to overlay a red dot on the ROC curve at your desired FPR level.  What threshold does this correspond to? At this specific FPR, do you think our model is good enough to real-life SPAM classification?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br>\n",
    "<br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "### Helper Functions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-16T04:47:55.108552Z",
     "start_time": "2018-03-16T04:47:55.092411Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mycolors = dict({\"blue\": \"steelblue\", \"red\": \"#a76c6e\", \"green\": \"#6a9373\", \"orange\": \"orange\"})\n",
    "\n",
    "def feature_hist(df, feat, feat_max):\n",
    "    \"\"\"\n",
    "    Function to plot SPAM vs HAM histograms for a given feature \n",
    "    \n",
    "    :param df: the DataFrame \n",
    "    :param feat: the feature name \n",
    "    :param feat_max: the largest values of feature to plot \n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=True, figsize=(10,8))\n",
    "    df.loc[df[feat] < feat_max].hist(column=feat, by=\"isSPAM\", ax=axes, bins=20, edgecolor=\"white\")\n",
    "    axes[0].set_title(\"HAM\", fontsize=16); axes[1].set_title(\"SPAM\", fontsize=16)\n",
    "    for ax in axes:\n",
    "        ax.grid(alpha=0.25)\n",
    "        ax.set_axisbelow(\"True\")\n",
    "        ax.set_xlabel(feat, fontsize=16)\n",
    "        ax.set_ylabel(\"frequency\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

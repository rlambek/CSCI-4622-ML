{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Feature Engineering\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder**:  Go to the botttom of the notebook and shift-enter the [helper functions](#helpers)\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The success of a machine learning algorithm on a predictive problem is highly dependent on the way you as the practitioner present the data. Consider the following example. \n",
    "\n",
    "### Problem 1: Intuition\n",
    "***\n",
    "Suppose that you want to train a model to predict whether it is possible to drive between two cities in a single day.  The raw data includes the latitude and longitude of the two cities and the training data is labeled with $\\texttt{Yes}$ for is drivable and $\\texttt{No}$ for is not drivable.  One particular training set my look like \n",
    "\n",
    "|$\\texttt{CITY 1 LAT.}$ | $\\texttt{CITY 1 LNG.}$ |$\\texttt{CITY 2 LAT.}$ | $\\texttt{CITY 2 LNG.}$ | $\\texttt{DRIVABLE}$? | \n",
    "|:----:|:----:|:----:|:----:|:----:|\n",
    "| 123.24 |46.71\t| 121.33| 47.34\t| Yes |\n",
    "|123.24\t|56.91\t|121.33\t|55.23\t|Yes |\n",
    "|123.24\t|46.71\t|121.33\t|55.34\t|No |\n",
    "|123.24\t|46.71\t|130.99\t|47.34\t|No |\n",
    "\n",
    "**Q**: Given the following features, do you expect a linear classifier like Logistic Regression to be successful? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: What features could you create that *would* be correlated with the correct classification? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**: Could we come up with a process to do this automatically?  Next question:  should we come up with a process to do this automatically? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Problem 2: Transformations on Continuous Data \n",
    "***\n",
    "\n",
    "Consider the case when you're trying to model quality of life of a person from survey data which asks a multitude of things like $\\texttt{income}$, $\\texttt{education level}$, $\\texttt{num children}$, etc.  As part of data exploration, you might try plotting the distributions of the raw data by feature individually.  A histogram of a potential data set for income might look as follows:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:26:19.913493Z",
     "start_time": "2018-03-07T08:26:19.601091Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_inc = income_data()\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "n, bins, patches = ax.hist(x_inc, 15, normed=1, facecolor=mycolors[\"red\"], alpha=0.75, edgecolor=\"white\")\n",
    "ax.set_xlabel(\"income in tens of thousands\", fontsize=16)\n",
    "ax.set_ylabel(\"frequency\", fontsize=16);\n",
    "ax.set_title(\"Income Frequency\", fontsize=20);\n",
    "ax.grid(alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like we would expect for income.  There are lots of people at the low end of the spectrum, a few more in the middle, and very few in the high income categories.  \n",
    "\n",
    "There are two things to consider here.  First, lots of ML models assume that your input features are generally normally distributed.  Second, from a feature engineering perspective, we can think about how much income actually affects happiness.  It seems reasonable to believe that once you get to a certain level, increasing income has a diminishing effect on happiness.  \n",
    "\n",
    "Both of these viewpoints motivate us to try a log transformation on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:26:24.208988Z",
     "start_time": "2018-03-07T08:26:23.958065Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_inc_log = np.log(x_inc)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,6))\n",
    "n, bins, patches = ax.hist(x_inc_log, 15, normed=1, facecolor=mycolors[\"blue\"], alpha=0.75, edgecolor=\"white\")\n",
    "ax.set_xlabel(\"log(income in thousands)\", fontsize=16)\n",
    "ax.set_ylabel(\"frequency\", fontsize=16);\n",
    "ax.set_title(\"Income Frequency\", fontsize=20);\n",
    "ax.grid(alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results in a distribution that looks fairly Gaussian, which might perform better in an machine learning model. \n",
    "\n",
    "<br>\n",
    "\n",
    "### Problem 3: Categorical Data \n",
    "*** \n",
    "\n",
    "Encoding categorical data can be tricky.  Consider the case when you have a raw feature in your model that corresponds to a person's hair color.  Possible values might be $\\texttt{blonde}$, $\\texttt{brunette}$, $\\texttt{redhead}$.  How should we encode these as numerical models in a ML algorithm? \n",
    "\n",
    "A natural (but misleading) thing to do would be to assign an integer to each possible value of the feature.  For instance, we could do \n",
    "\n",
    "|Hair Color| Feature|\n",
    "|:-------:|:------:|\n",
    "|blonde| 0 |\n",
    "|brunette | 1 | \n",
    "|redhead | 2|\n",
    "\n",
    "**Q**:  What is potentially wrong with this encoding, particularly in a regression context? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to fix this is create binary features corresponding to each religion.  That is, we create a binary $\\texttt{IsBlonde}$ variable, a binary $\\texttt{IsBrunette}$ variable, etc.  We then have \n",
    "\n",
    "|Religion| $\\texttt{IsBlonde}$ | $\\texttt{IsBrunette}$ | $\\texttt{IsRedhead}$| \n",
    "|:-------:|:------:|:------:|:------:|\n",
    "|Blonde| 1 | 0 | 0 | \n",
    "|Brunette | 0 | 1 | 0 | \n",
    "| Redhead | 0| 0 | 1 \n",
    "\n",
    "This process is called *one-hot-encoding* and is very frequently used to encode categorical data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "\n",
    "### Problem 4: Temporal Data \n",
    "*** \n",
    "\n",
    "Suppose that you're trying to train a model to predict that amount of foot-traffic at the 29th Street Mall.  Mall managers might be interested in such a model to predict the amount of janitorial and security services they need to employ at different times.  \n",
    "\n",
    "Suppose your training data consists of measurements of the amount of foot traffic at the mall and the date/time stamps that they were measured.  For instance, a training set might look like \n",
    "\n",
    "|$\\texttt{date_time_stamp}$| $\\texttt{FootTraffic}$|\n",
    "|:-------:|:------:|\n",
    "|$\\texttt{2015-11-12-20:00}$| 70|\n",
    "|$\\texttt{2015-06-10-21:00}$| 100|\n",
    "|$\\texttt{2015-08-02-12:00}$| 120|\n",
    "|$\\texttt{2015-12-22-12:00}$| 20|\n",
    "\n",
    "\n",
    "**Q**: How might you create meaningful features on the $\\texttt{date_time_stamp}$ data that would be useful for prediction? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### Problem 5: Part-of-Speech-Tagging\n",
    "*This problem and associated code was adapted from Jordan Boyd-Graber*\n",
    "***\n",
    "\n",
    "In computational linguistics, part-of-speech tagging (POST) is the process of marking a word in a text as a particular part of speech (e.g. noun, verb, adjective, etc), based on both its definition and its context. \n",
    "\n",
    "In this problem we will work with the <a href=\"https://en.wikipedia.org/wiki/Brown_Corpus\">Brown Corpus</a>, a compilation of 500 samples of English-language text totaling over a million words. The Brown Corpus is available through python's <a href=\"http://www.nltk.org/\">Natural Language Toolkit</a>.  Each word in the corpus has been tagged as: \n",
    "\n",
    "|type|symbol|\n",
    "|:--:|:----:|\n",
    "|adjective| JJ|\n",
    "|noun|NN|\n",
    "|pronoun|PP|\n",
    "|adverb|RB|\n",
    "|verb|VB|\n",
    "\n",
    "For the classification we will use simple Logistic Regression and focus on making iterative improvements by adding good features to our model.  The code for this problem is located in the helper functions section below.  Scroll down now and take a look at the code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a Baseline**: When starting to evaluate the usefulness of features, it is usually a good idea to create a baseline.  That is, run your model with little to no features and see how the model performs.  The following code will run logistic regression with only a bias feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:27:21.463221Z",
     "start_time": "2018-03-07T08:27:12.904544Z"
    }
   },
   "outputs": [],
   "source": [
    "part_of_speech(limit=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so now we know that simply making predictions based on the number of occurrences of each type of speech leads to a *training accuracy* of around 52% and a *validation accuracy* of around 56%.  Hopefully we can improve on this by actually giving the model some useful features.  \n",
    "\n",
    "The obvious choice is to actually tell the model what the words is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:33:42.523535Z",
     "start_time": "2018-03-07T08:33:37.948287Z"
    }
   },
   "outputs": [],
   "source": [
    "part_of_speech(limit=500, word=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that seems more reasonable.  Now you should have a training accuracy of around 96% and a validation accuracy of around 79%.  It looks like using the words alone as features induces some overfitting on the training set. Let's see if we can think of new features that we could include that might help.  \n",
    "\n",
    "Here is where you have to use your brain to do feature engineering!  \n",
    "\n",
    "The code has output some useful information that you can use to do error analysis and hopefully come up with some useful features.  \n",
    "\n",
    "The top of the output gives you examples of the features that were used for several examples.  Since we only used the words as features, each example only includes the word itself. \n",
    "\n",
    "The next useful piece of information is shown in the *confusion matrix*. Sci-Kit Learn's confusion matrix function returns a matric $C$ such that $C_{ij}$ gives the number of examples known to be in group $i$ that were labeled as group $j$.  From the confusion matrix in the output we see that, in particular, the model is classifying a lot of words that should be verbs as nouns.   \n",
    "\n",
    "Now, based on this knowledge you might have some ideas about new features you can include to combat this error, but maybe you don't?  It's almost always a good idea to dig into the actual data and look at *specific* examples that your model has misclassified.  To help you with this, the code has printed some of the most common misclassifications.  \n",
    "\n",
    "**Q**: Looking at the common misclassifications, can you think of a good new feature to add? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your new feature to the model and see how it does! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:33:52.417253Z",
     "start_time": "2018-03-07T08:33:47.797629Z"
    }
   },
   "outputs": [],
   "source": [
    "part_of_speech(limit=500, word=True, all_before=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**:  Did your model do better on the test data?  Take a look at the confusion matrix and the examples of misclassifications and see if you can think of another new feature to add! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part_of_speech(limit=500, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q**:  What's your performance like now?  Repeat this iterative process of adding new features until you're happy with your model (or you've exhausted the number of features available in the code) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part_of_speech(limit=500, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "\n",
    "<a id='helpers'></a>\n",
    "\n",
    "<br> \n",
    "\n",
    "### Helper Functions\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-07T08:34:12.254786Z",
     "start_time": "2018-03-07T08:34:11.230116Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import string\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('brown')\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import brown\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import seaborn as sn \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "mycolors = {\"blue\": \"steelblue\", \"red\": \"#a76c6e\", \"green\": \"#6a9373\"}\n",
    "\n",
    "\n",
    "def normalize_tags(tag):\n",
    "    if not tag or not tag[0] in \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\":\n",
    "        return \"PUNC\"\n",
    "    else:\n",
    "        return tag[:2]\n",
    "\n",
    "\n",
    "kTAGSET = [\"\", \"JJ\", \"NN\", \"PP\", \"RB\", \"VB\"]\n",
    "\n",
    "class Analyzer:\n",
    "    def __init__(self, word, before, after, prev, next, char, dict):\n",
    "        self.word = word\n",
    "        self.after = after\n",
    "        self.before = before\n",
    "        self.prev = prev\n",
    "        self.next = next\n",
    "        self.dict = dict\n",
    "        self.char = char\n",
    "\n",
    "    def __call__(self, feature_string):\n",
    "        feats = feature_string.split()\n",
    "\n",
    "        if self.word:\n",
    "            yield feats[0]\n",
    "\n",
    "        if self.after:\n",
    "            for ii in [x for x in feats if x.startswith(\"A:\")]:\n",
    "                yield ii\n",
    "        if self.before:\n",
    "            for ii in [x for x in feats if x.startswith(\"B:\")]:\n",
    "                yield ii\n",
    "        if self.prev:\n",
    "            for ii in [x for x in feats if x.startswith(\"P:\")]:\n",
    "                yield ii\n",
    "        if self.next:\n",
    "            for ii in [x for x in feats if x.startswith(\"N:\")]:\n",
    "                yield ii\n",
    "        if self.dict:\n",
    "            for ii in [x for x in feats if x.startswith(\"D:\")]:\n",
    "                yield ii\n",
    "        if self.char:\n",
    "            for ii in [x for x in feats if x.startswith(\"C:\")]:\n",
    "                yield ii\n",
    "                \n",
    "def example(sentence, position):\n",
    "        word = sentence[position][0]\n",
    "        ex = word\n",
    "        tag = normalize_tags(sentence[position][1])\n",
    "        if tag in kTAGSET:\n",
    "            target = kTAGSET.index(tag)\n",
    "        else:\n",
    "            target = None\n",
    "\n",
    "        if position > 0:\n",
    "            prev = \" P:%s\" % sentence[position - 1][0]\n",
    "        else:\n",
    "            prev = \"\"\n",
    "\n",
    "        if position < len(sentence) - 1:\n",
    "            next = \" N:%s\" % sentence[position + 1][0]\n",
    "        else:\n",
    "            next = ''\n",
    "\n",
    "        all_before = \" \" + \" \".join([\"B:%s\" % x[0] for x in sentence[:position]])\n",
    "        all_after = \" \" + \" \".join([\"A:%s\" % x[0] for x in sentence[(position + 1):]])\n",
    "\n",
    "        dictionary = [\"D:ADJ\"] * len(wn.synsets(word, wn.ADJ)) + \\\n",
    "          [\"D:ADV\"] * len(wn.synsets(word, wn.ADV)) + \\\n",
    "          [\"D:VERB\"] * len(wn.synsets(word, wn.VERB)) + \\\n",
    "          [\"D:NOUN\"] * len(wn.synsets(word, wn.NOUN))\n",
    "\n",
    "        dictionary = \" \" + \" \".join(dictionary)\n",
    "\n",
    "        char = ' '\n",
    "        padded_word = \"~%s^\" % sentence[position][0]\n",
    "        for ngram_length in range(2, 5):\n",
    "            char += ' ' + \" \".join(\"C:%s\" % \"\".join(cc for cc in x)\n",
    "                                   for x in ngrams(padded_word, ngram_length))\n",
    "        ex += char\n",
    "\n",
    "        ex += prev\n",
    "        ex += next\n",
    "        ex += all_after\n",
    "        ex += all_before\n",
    "        ex += dictionary\n",
    "\n",
    "        return ex, target\n",
    "    \n",
    "def all_examples(limit, train=True):\n",
    "    sent_num = 0\n",
    "    for ii in brown.tagged_sents():\n",
    "        sent_num += 1\n",
    "        if limit > 0 and sent_num > limit:\n",
    "            break\n",
    "\n",
    "        for jj in range(len(ii)):\n",
    "            ex, tgt = example(ii, jj)\n",
    "            if tgt:\n",
    "                if train and sent_num % 5 != 0:\n",
    "                    yield ex, tgt\n",
    "                if not train and sent_num % 5 == 0:\n",
    "                    yield ex, tgt\n",
    "                    \n",
    "def accuracy(classifier, x, y, examples):\n",
    "    predictions = classifier.predict(x)\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "\n",
    "    print(\"Accuracy: %f\" % accuracy_score(y, predictions))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\\n\")\n",
    "    print(\"\\t\".join(kTAGSET[1:]))\n",
    "    for ii in cm:\n",
    "        print(\"\\t\".join(str(x) for x in ii))\n",
    "\n",
    "    errors = defaultdict(int)\n",
    "    for ii, ex_tuple in enumerate(examples):\n",
    "        ex, tgt = ex_tuple\n",
    "        if tgt != predictions[ii]:\n",
    "            errors[(ex.split()[0], kTAGSET[predictions[ii]], kTAGSET[tgt])] += 1\n",
    "\n",
    "    print(\"\\nSome misclassified examples:\\n\")\n",
    "    for ww, cc in sorted(errors.items(), key=operator.itemgetter(1), reverse=True)[:10]:\n",
    "        print(\"word: {:10s}  prediced pos: {:2s}      true pos: {:2s}\".format(ww[0], ww[1], ww[2]))\n",
    "        \n",
    "def part_of_speech(**kwargs):\n",
    "    word = kwargs.get(\"word\", False)\n",
    "    all_before = kwargs.get(\"all_before\", False)\n",
    "    all_after = kwargs.get(\"all_after\", False)\n",
    "    one_before = kwargs.get(\"one_before\", False)\n",
    "    one_after = kwargs.get(\"one_after\", False)\n",
    "    characters = kwargs.get(\"characters\", False)\n",
    "    dictionary = kwargs.get(\"dictionary\", False)\n",
    "    limit= kwargs.get(\"limit\",-1)\n",
    "    \n",
    "    analyzer = Analyzer(word, all_before, all_after, one_before, one_after, characters, dictionary)\n",
    "    \n",
    "    vectorizer = HashingVectorizer(analyzer=analyzer)\n",
    "\n",
    "    x_train = vectorizer.fit_transform(ex for ex, tgt in all_examples(limit))\n",
    "    x_valid = vectorizer.fit_transform(ex for ex, tgt in all_examples(limit, train=False))\n",
    "    \n",
    "    print(\"Example Features:\")\n",
    "    exstr = \"\\n\"\n",
    "    for ex, tgt in all_examples(1):\n",
    "        exstr += \" \".join(analyzer(ex)) + \"\\n\"\n",
    "    if exstr.replace(\" \", \"\").replace(\"\\n\", \"\") == \"\":\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(exstr)\n",
    "\n",
    "    y_train = np.array(list(tgt for ex, tgt in all_examples(limit)))\n",
    "    y_valid = np.array(list(tgt for ex, tgt in all_examples(limit, train=False)))\n",
    "\n",
    "    lr = SGDClassifier(loss='log', penalty='l2', tol=None, max_iter=5, shuffle=True)\n",
    "    lr.fit(x_train, y_train)\n",
    "\n",
    "    print(\"\\nTraining Set\\n-------------------------\")\n",
    "    accuracy(lr, x_train, y_train, all_examples(limit))\n",
    "    print(\"\\nValidation Set\\n--------------------\")\n",
    "    accuracy(lr, x_valid, y_valid, all_examples(limit, train=False))\n",
    "    \n",
    "np.random.seed(1234)\n",
    "    \n",
    "def income_data(N=200):\n",
    "    x = 1.1*np.random.normal(size=N)\n",
    "    y = np.exp(x)\n",
    "    return y\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".MathJax nobr>span.math>span{border-left-width:0 !important};\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
